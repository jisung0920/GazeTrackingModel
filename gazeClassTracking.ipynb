{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gazeData(data.Dataset):\n",
    "    def __init__(self, dataset, imSize=(224,224)):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.imSize = imSize\n",
    "        \n",
    "        self.transformImg = transforms.Compose([transforms.Resize(self.imSize)\n",
    "                                                ,transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "        self.classLabel = [0]*16\n",
    "#         self.transformPoint = transforms.Compose([\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         index = self.indices[index]\n",
    "\n",
    "        filePath = self.dataset['file'][index]\n",
    "        image = Image.open(filePath).convert('RGB')\n",
    "        image = self.transformImg(image)   \n",
    "\n",
    "        labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        labels[self.dataset['location'][index]] = 1\n",
    "        labels = torch.FloatTensor(labels)\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "        \n",
    "        \n",
    "        return sample\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=16, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vggface(pretrained=False, **kwargs):\n",
    "    \"\"\"VGGFace model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns pre-trained model \n",
    "    \"\"\"\n",
    "    model = VggFace(**kwargs)\n",
    "    if pretrained:\n",
    "        state = torch.utils.model_zoo.load_url(MODEL_URL)\n",
    "        model.load_state_dict(state)\n",
    "    return model\n",
    "\n",
    "\n",
    "class VggFace(torch.nn.Module):\n",
    "    def __init__(self, classes=16):\n",
    "        \"\"\"VGGFace model.\n",
    "        Face recognition network.  It takes as input a Bx3x224x224\n",
    "        batch of face images and gives as output a BxC score vector\n",
    "        (C is the number of identities).\n",
    "        Input images need to be scaled in the 0-1 range and then \n",
    "        normalized with respect to the mean RGB used during training.\n",
    "        Args:\n",
    "            classes (int): number of identities recognized by the\n",
    "            network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = _ConvBlock(3, 64, 64)\n",
    "        self.conv2 = _ConvBlock(64, 128, 128)\n",
    "        self.conv3 = _ConvBlock(128, 256, 256, 256)\n",
    "        self.conv4 = _ConvBlock(256, 512, 512, 512)\n",
    "        self.conv5 = _ConvBlock(512, 512, 512, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(7 * 7 * 512, 4096)\n",
    "        self.fc2 = torch.nn.Linear(4096, 4096)\n",
    "        self.fc3 = torch.nn.Linear(4096, classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class _ConvBlock(torch.nn.Module):\n",
    "    \"\"\"A Convolutional block.\"\"\"\n",
    "\n",
    "    def __init__(self, *units):\n",
    "        \"\"\"Create a block with len(units) - 1 convolutions.\n",
    "        convolution number i transforms the number of channels from \n",
    "        units[i - 1] to units[i] channels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(in_, out, 3, 1, 1)\n",
    "            for in_, out in zip(units[:-1], units[1:])\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Each convolution is followed by a ReLU, then the block is\n",
    "        # concluded by a max pooling.\n",
    "        for c in self.convs:\n",
    "            x = F.relu(c(x))\n",
    "        return F.max_pool2d(x, 2, 2, 0, ceil_mode=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, planes, compress_rate):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(planes, planes // compress_rate, kernel_size=1, stride=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(planes // compress_rate, planes, kernel_size=1, stride=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = F.avg_pool2d(module_input, kernel_size=module_input.size(2))\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        # SENet\n",
    "        compress_rate = 16\n",
    "        # self.se_block = SEModule(planes * 4, compress_rate)  # this is not used.\n",
    "        self.conv4 = nn.Conv2d(planes * 4, planes * 4 // compress_rate, kernel_size=1, stride=1, bias=True)\n",
    "        self.conv5 = nn.Conv2d(planes * 4 // compress_rate, planes * 4, kernel_size=1, stride=1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "\n",
    "        ## senet\n",
    "        out2 = F.avg_pool2d(out, kernel_size=out.size(2))\n",
    "        out2 = self.conv4(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.conv5(out2)\n",
    "        out2 = self.sigmoid(out2)\n",
    "        # out2 = self.se_block.forward(out)  # not used\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out2 * out + residual\n",
    "        # out = out2 + residual  # not used\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=16, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(SENet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def senet50(**kwargs):\n",
    "    \"\"\"Constructs a SENet-50 model.\n",
    "    \"\"\"\n",
    "    model = SENet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpointClass.pth.tar'):\n",
    "    CHECKPOINTS_PATH = './gazeClassCheckpoint'\n",
    "    if not os.path.isdir(CHECKPOINTS_PATH):\n",
    "        os.makedirs(CHECKPOINTS_PATH, 0o777)\n",
    "    bestFilename = os.path.join(CHECKPOINTS_PATH, 'best_' + filename)\n",
    "    filename = os.path.join(CHECKPOINTS_PATH, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, bestFilename)\n",
    "        \n",
    "def load_checkpoint(filename='./gazeClassCheckpoint/checkpointClass.pth.tar'):\n",
    "    print(filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        return None\n",
    "    state = torch.load(filename)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.0001 * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.state_dict()['param_groups']:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 16\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "weight_decay = 1e-4\n",
    "best_loss = 1000\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gaze = pd.read_csv('gazeClassData.csv')\n",
    "df_gaze =df_gaze.drop(['index'],axis=1)\n",
    "\n",
    "df_train=df_gaze.sample(frac=0.9,random_state=100) \n",
    "df_tmp= df_gaze.drop(df_train.index)\n",
    "\n",
    "df_train.reset_index(inplace=True)\n",
    "df_tmp.reset_index(inplace=True)\n",
    "\n",
    "df_val = df_tmp.sample(frac=0.5, random_state = 100)\n",
    "df_test = df_tmp.drop(df_val.index)\n",
    "\n",
    "df_val.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>438573</td>\n",
       "      <td>2</td>\n",
       "      <td>./data/01849/frames/00743.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703392</td>\n",
       "      <td>12</td>\n",
       "      <td>./data/02945/frames/00833.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158947</td>\n",
       "      <td>11</td>\n",
       "      <td>./data/00831/frames/00307.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779797</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/03312/frames/00838.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587944</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/02416/frames/00086.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  location                           file\n",
       "0  438573         2  ./data/01849/frames/00743.jpg\n",
       "1  703392        12  ./data/02945/frames/00833.jpg\n",
       "2  158947        11  ./data/00831/frames/00307.jpg\n",
       "3  779797        15  ./data/03312/frames/00838.jpg\n",
       "4  587944        15  ./data/02416/frames/00086.jpg"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 737485 val 40972 test 40971\n"
     ]
    }
   ],
   "source": [
    "print('train',len(df_train),'val',len(df_val),'test',len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = gazeData(dataset=df_train)\n",
    "dataVal = gazeData(dataset=df_val)\n",
    "dataTest = gazeData(dataset=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataTrain,\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        dataVal,\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataTest,\n",
    "        batch_size=1, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "# model = senet50()\n",
    "# model =vggface()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()\n",
    "cudnn.benchmark = True   \n",
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gazeClassCheckpoint/checkpointClass.pth.tar\n",
      "Loading checkpoint for epoch 00002 with loss 0.00019 (which is the mean squared error not the actual linear error)...\n"
     ]
    }
   ],
   "source": [
    "epoch =0\n",
    "saved = load_checkpoint()\n",
    "if saved:\n",
    "    print('Loading checkpoint for epoch %05d with loss %.5f (which is the mean squared error not the actual linear error)...' % (saved['epoch'], saved['best_prec1']))\n",
    "    state = saved['state_dict']\n",
    "    try:\n",
    "        model.module.load_state_dict(state)\n",
    "    except:\n",
    "        model.load_state_dict(state)\n",
    "    epoch = saved['epoch']\n",
    "    best_prec1 = saved['best_prec1']\n",
    "else:\n",
    "    print('Warning: Could not read checkpoint!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion,optimizer, epoch):\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    running_loss = 0\n",
    "    for i,sample in enumerate(train_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(frame)\n",
    "        \n",
    "        loss = criterion(output, locationClass)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('Train [%d, %d / %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1,len(train_loader), running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            print(str(datetime.datetime.now().time()))\n",
    "\n",
    "def validate(val_loader, model, criterion,optimizer, epoch) :\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_loss = 0\n",
    "    for i,sample in enumerate(val_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(frame)\n",
    "        \n",
    "        loss = criterion(output, locationClass)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        if i % 200 == 0:   \n",
    "            print('Validate [%d, %5d / %5d ] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1,len(val_loader) , val_loss / (i+1)))\n",
    "            print(str(datetime.datetime.now().time()))\n",
    "        return val_loss/len(val_loader)\n",
    "    \n",
    "def TestData(test_loader, model) :\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i,sample in enumerate(test_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        output = model(frame)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += locationClass.size(0)\n",
    "        correct += (predicted == locationClass).sum().item()\n",
    "        \n",
    "    print('Test set: Accuracy: {:.2f}%'.format(100. * correct / len(test_loader.dataset)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EPOCH >',epoch)\n",
    "for epoch in range(epoch, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    val_loss = validate(val_loader, model, criterion,optimizer, epoch)\n",
    "    \n",
    "    TestData(test_loader,model)\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = val_loss < best_loss\n",
    "    best_loss = min(val_loss, best_loss)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_loss,\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        data,\n",
    "        batch_size=1, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "TestData(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
